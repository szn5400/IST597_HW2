{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1bd762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4008e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Define the One-hot Encoder\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "# Load MNIST data\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Fit and transform training data\n",
    "ohe.fit(y_train)\n",
    "transformed_train = ohe.transform(y_train).toarray()\n",
    "\n",
    "# Fit and transform testing data\n",
    "ohe.fit(y_test)\n",
    "transformed_test = ohe.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e28a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000, 10)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(x_train.shape))\n",
    "print('Y_train: ' + str(transformed_train.shape))\n",
    "print('X_test:  '  + str(x_test.shape))\n",
    "print('Y_test:  '  + str(transformed_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c6c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_mod = x_train.reshape(60000, 784)\n",
    "train_y_mod = transformed_train\n",
    "test_X_mod = x_test.reshape(10000, 784)\n",
    "test_y_mod = transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6057cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_input = 784\n",
    "size_hidden1 = 512\n",
    "size_hidden2 = 256\n",
    "size_output = 10\n",
    "number_of_train_examples = 60000\n",
    "number_of_test_examples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511b4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X_train = tf.keras.utils.normalize(train_X_mod, axis=1)\n",
    "y_train = train_y_mod\n",
    "X_test = test_X_mod\n",
    "y_test = test_y_mod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2814fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "# Split dataset into batches\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(128)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c30bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "  def __init__(self, size_input, size_hidden1, size_hidden2, size_output, device=None):\n",
    "    \"\"\"\n",
    "    size_input: int, size of input layer\n",
    "    size_hidden1: int, size of hidden layer 1\n",
    "    size_hidden2: int, size of hodden layer 2\n",
    "    size_output: int, size of output layer\n",
    "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
    "    \"\"\"\n",
    "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_output, self.device =\\\n",
    "    size_input, size_hidden1, size_hidden2, size_output, device\n",
    "    \n",
    "    # Initialize weights between input layer and hidden layer\n",
    "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
    "    # Initialize biases for hidden layer\n",
    "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
    "    # Initialize weights between input layer and hidden layer\n",
    "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
    "    # Initialize biases for hidden layer\n",
    "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
    "     # Initialize weights between hidden layer and output layer\n",
    "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output]))\n",
    "    # Initialize biases for output layer\n",
    "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
    "    \n",
    "    # Define variables to be updated during backpropagation\n",
    "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "    \n",
    "  def forward(self, X):\n",
    "    \"\"\"\n",
    "    forward pass\n",
    "    X: Tensor, inputs\n",
    "    \"\"\"\n",
    "    if self.device is not None:\n",
    "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
    "        self.y = self.compute_output(X)\n",
    "    else:\n",
    "      self.y = self.compute_output(X)\n",
    "      \n",
    "    return self.y\n",
    "  \n",
    "  def loss(self, y_pred, y_true):\n",
    "    '''\n",
    "    y_pred - Tensor of shape (batch_size, size_output)\n",
    "    y_true - Tensor of shape (batch_size, size_output)\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    #return tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
    "    #print(y_true_tf)\n",
    "    #print(y_pred_tf)\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    loss_val = cce(y_true_tf, y_pred_tf)\n",
    "    regularizer = tf.nn.l2_loss(self.W1)+tf.nn.l2_loss(self.W2)\n",
    "    loss_val = tf.reduce_mean(loss_val + 0.01 * regularizer)\n",
    "    \n",
    "    #print(loss_val)\n",
    "    return loss_val\n",
    "\n",
    "  def accuracy(self, y_pred, y_true):\n",
    "    '''\n",
    "    y_pred - Tensor of shape (batch_size, size_output)\n",
    "    y_true - Tensor of shape (batch_size, size_output)\n",
    "    '''\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    #y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
    "    print(y_true_tf)\n",
    "    print(y_pred_tf)\n",
    "    ## CALCULATING COST AND ACCURACY\n",
    "    #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_preds, labels=y))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    #print(correct_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #print(ac)\n",
    "    return accuracy\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    #y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)    \n",
    "    correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    #print(correct_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "  \n",
    "  def backward(self, X_train, y_train):\n",
    "    \"\"\"\n",
    "    backward pass\n",
    "    \"\"\"\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "    with tf.GradientTape() as tape:\n",
    "      predicted = self.forward(X_train)\n",
    "      current_loss = self.loss(predicted, y_train)\n",
    "    grads = tape.gradient(current_loss, self.variables)\n",
    "    optimizer.apply_gradients(zip(grads, self.variables))\n",
    "        \n",
    "        \n",
    "  def compute_output(self, X):\n",
    "    \"\"\"\n",
    "    Custom method to obtain output tensor during forward pass\n",
    "    \"\"\"\n",
    "    # Cast X to float32\n",
    "    X_tf = tf.cast(X, dtype=tf.float32)\n",
    "    #Remember to normalize your dataset before moving forward\n",
    "    # Compute values in hidden layer1\n",
    "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "    hhat1 = tf.nn.relu(what1)\n",
    "    #hhat1_1 = tf.nn.dropout(hhat1, keep_prob)\n",
    "    #hhat1_1 = tf.nn.dropout(hhat1, 0.1)\n",
    "    # Compute values in hidden layer2\n",
    "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
    "    hhat2 = tf.nn.relu(what2)\n",
    "    # Compute output\n",
    "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
    "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
    "    #Second add tf.Softmax(output) and then return this variable\n",
    "    output = tf.nn.softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "455ab2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a4006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 1 - Average celoss:= 100.69004166666667- Acc:= 0.28679966926574707 \n",
      "Number of Epoch = 2 - Average celoss:= 55.37105416666667- Acc:= 0.4706994593143463 \n",
      "Number of Epoch = 3 - Average celoss:= 30.418095833333332- Acc:= 0.6633663773536682 \n",
      "Number of Epoch = 4 - Average celoss:= 16.682696875- Acc:= 0.8131479620933533 \n",
      "Number of Epoch = 5 - Average celoss:= 9.133382291666667- Acc:= 0.8845106363296509 \n",
      "Number of Epoch = 6 - Average celoss:= 5.011066666666666- Acc:= 0.905443012714386 \n",
      "Number of Epoch = 7 - Average celoss:= 2.7593484375- Acc:= 0.909942626953125 \n",
      "Number of Epoch = 8 - Average celoss:= 1.5281861979166667- Acc:= 0.9049265384674072 \n",
      "Number of Epoch = 9 - Average celoss:= 0.8536423177083333- Acc:= 0.9033923149108887 \n",
      "Number of Epoch = 10 - Average celoss:= 0.48336640625- Acc:= 0.9024938344955444 \n",
      "Number of Epoch = 11 - Average celoss:= 0.2802035481770833- Acc:= 0.9019267559051514 \n",
      "Number of Epoch = 12 - Average celoss:= 0.168264208984375- Acc:= 0.9042755365371704 \n",
      "Number of Epoch = 13 - Average celoss:= 0.10653858235677083- Acc:= 0.904093325138092 \n",
      "Number of Epoch = 14 - Average celoss:= 0.07210687662760416- Acc:= 0.9069597721099854 \n",
      "Number of Epoch = 15 - Average celoss:= 0.05306108805338541- Acc:= 0.907842218875885 \n",
      "Number of Epoch = 16 - Average celoss:= 0.04213563232421875- Acc:= 0.9093258380889893 \n",
      "Number of Epoch = 17 - Average celoss:= 0.03585647786458333- Acc:= 0.9129418730735779 \n",
      "Number of Epoch = 18 - Average celoss:= 0.03212316691080729- Acc:= 0.9132598638534546 \n",
      "Number of Epoch = 19 - Average celoss:= 0.02983394978841146- Acc:= 0.9148086905479431 \n",
      "Number of Epoch = 20 - Average celoss:= 0.028313956705729167- Acc:= 0.9178081750869751 \n",
      "Number of Epoch = 21 - Average celoss:= 0.027268052164713542- Acc:= 0.9200072288513184 \n",
      "Number of Epoch = 22 - Average celoss:= 0.026487349446614582- Acc:= 0.9226911067962646 \n",
      "Number of Epoch = 23 - Average celoss:= 0.025943863932291665- Acc:= 0.9234408140182495 \n",
      "Number of Epoch = 24 - Average celoss:= 0.02550653076171875- Acc:= 0.925340473651886 \n",
      "Number of Epoch = 25 - Average celoss:= 0.025206986490885416- Acc:= 0.9258913397789001 \n",
      "Number of Epoch = 26 - Average celoss:= 0.0248893310546875- Acc:= 0.9275401830673218 \n",
      "Number of Epoch = 27 - Average celoss:= 0.02460213826497396- Acc:= 0.9292235374450684 \n",
      "Number of Epoch = 28 - Average celoss:= 0.024356815592447918- Acc:= 0.9292404651641846 \n",
      "Number of Epoch = 29 - Average celoss:= 0.024067399088541667- Acc:= 0.9316065311431885 \n",
      "Number of Epoch = 30 - Average celoss:= 0.023863112386067708- Acc:= 0.9312397241592407 \n",
      "\n",
      "Total time taken (in seconds): 1766.13\n"
     ]
    }
   ],
   "source": [
    "# Initialize model using CPU\n",
    "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_output, device='cpu')\n",
    "\n",
    "# Array to store accuracy and loss\n",
    "loss_with_epoch = []\n",
    "acc_with_epoch = []\n",
    "\n",
    "time_start = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  ac = 0\n",
    "  count = 0\n",
    "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
    "  lt = 0\n",
    "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
    "  for inputs, outputs in train_ds:\n",
    "    preds = mlp_on_cpu.forward(inputs)\n",
    "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
    "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
    "    mlp_on_cpu.backward(inputs, outputs)\n",
    "    ac = ac+mlp_on_cpu.accuracy(preds, outputs)\n",
    "    #ac = mlp_on_cpu.accuracy(preds, outputs)\n",
    "    count += 1\n",
    "  print('Number of Epoch = {} - Average celoss:= {}- Acc:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], ac/count))\n",
    "  loss_with_epoch.append(np.sum(loss_total) / X_train.shape[0])\n",
    "  acc_with_epoch.append(ac/count)\n",
    "time_taken = time.time() - time_start\n",
    "\n",
    "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
    "#For per epoch_time = Total_Time / Number_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34e755bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = [i for i in range(1,31)]\n",
    "line1, = plt.plot(x, acc_with_epoch, label='accr')\n",
    "line2, = plt.plot(x, loss_with_epoch, label='ce loss')\n",
    "#plt.plot(x, acc_with_epoch, label='accr')\n",
    "plt.legend(handles=[line1, line2], loc='best')\n",
    "plt.grid(b=True, color='aqua', alpha=0.6, linestyle='dashdot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e990e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test celoss: 0.1493 and accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
    "#test_loss_total = 0.0\n",
    "for inputs, outputs in test_ds:\n",
    "  preds = mlp_on_cpu.forward(inputs)\n",
    "  #b = mlp_on_default.loss(preds, outputs)\n",
    "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
    "  ac = mlp_on_cpu.accuracy(preds, outputs)\n",
    "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
    "# print(X_train.shape[0])\n",
    "# print(test_loss_total.numpy())\n",
    "# print(b)\n",
    "print('Test celoss: {:.4f} and accuracy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0], ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad003a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
