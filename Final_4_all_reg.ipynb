{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04d9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f110e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Define the One-hot Encoder\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "# Load MNIST data\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Fit and transform training data\n",
    "ohe.fit(y_train)\n",
    "transformed_train = ohe.transform(y_train).toarray()\n",
    "\n",
    "# Fit and transform testing data\n",
    "ohe.fit(y_test)\n",
    "transformed_test = ohe.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b98a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000, 10)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(x_train.shape))\n",
    "print('Y_train: ' + str(transformed_train.shape))\n",
    "print('X_test:  '  + str(x_test.shape))\n",
    "print('Y_test:  '  + str(transformed_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4871e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_mod = x_train.reshape(60000, 784)\n",
    "train_y_mod = transformed_train\n",
    "test_X_mod = x_test.reshape(10000, 784)\n",
    "test_y_mod = transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937068cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_input = 784\n",
    "size_hidden1 = 512\n",
    "size_hidden2 = 256\n",
    "size_output = 10\n",
    "number_of_train_examples = 60000\n",
    "number_of_test_examples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c30a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X_train = tf.keras.utils.normalize(train_X_mod, axis=1)\n",
    "y_train = train_y_mod\n",
    "X_test = test_X_mod\n",
    "y_test = test_y_mod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d8d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "# Split dataset into batches\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(128)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8257b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "  def __init__(self, size_input, size_hidden1, size_hidden2, size_output, device=None):\n",
    "    \"\"\"\n",
    "    size_input: int, size of input layer\n",
    "    size_hidden1: int, size of hidden layer 1\n",
    "    size_hidden2: int, size of hodden layer 2\n",
    "    size_output: int, size of output layer\n",
    "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
    "    \"\"\"\n",
    "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_output, self.device =\\\n",
    "    size_input, size_hidden1, size_hidden2, size_output, device\n",
    "    \n",
    "    # Initialize weights between input layer and hidden layer\n",
    "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
    "    # Initialize biases for hidden layer\n",
    "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
    "    # Initialize weights between input layer and hidden layer\n",
    "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
    "    # Initialize biases for hidden layer\n",
    "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
    "     # Initialize weights between hidden layer and output layer\n",
    "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output]))\n",
    "    # Initialize biases for output layer\n",
    "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
    "    \n",
    "    # Define variables to be updated during backpropagation\n",
    "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "    \n",
    "  def forward(self, X):\n",
    "    \"\"\"\n",
    "    forward pass\n",
    "    X: Tensor, inputs\n",
    "    \"\"\"\n",
    "    if self.device is not None:\n",
    "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
    "        self.y = self.compute_output(X)\n",
    "    else:\n",
    "      self.y = self.compute_output(X)\n",
    "      \n",
    "    return self.y\n",
    "  \n",
    "  def loss(self, y_pred, y_true):\n",
    "    '''\n",
    "    y_pred - Tensor of shape (batch_size, size_output)\n",
    "    y_true - Tensor of shape (batch_size, size_output)\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    #return tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
    "    #print(y_true_tf)\n",
    "    #print(y_pred_tf)\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    loss_val = cce(y_true_tf, y_pred_tf)\n",
    "    regularizer = tf.nn.l2_loss(self.W1)+tf.nn.l2_loss(self.W2)\n",
    "    loss_val = tf.reduce_mean(loss_val + 0.01 * regularizer)\n",
    "    \n",
    "    #print(loss_val)\n",
    "    return loss_val\n",
    "\n",
    "  def accuracy(self, y_pred, y_true):\n",
    "    '''\n",
    "    y_pred - Tensor of shape (batch_size, size_output)\n",
    "    y_true - Tensor of shape (batch_size, size_output)\n",
    "    '''\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    #y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
    "    print(y_true_tf)\n",
    "    print(y_pred_tf)\n",
    "    ## CALCULATING COST AND ACCURACY\n",
    "    #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_preds, labels=y))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    #print(correct_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #print(ac)\n",
    "    return accuracy\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    #y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)    \n",
    "    correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    #print(correct_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "  \n",
    "  def backward(self, X_train, y_train):\n",
    "    \"\"\"\n",
    "    backward pass\n",
    "    \"\"\"\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "    with tf.GradientTape() as tape:\n",
    "      predicted = self.forward(X_train)\n",
    "      current_loss = self.loss(predicted, y_train)\n",
    "    grads = tape.gradient(current_loss, self.variables)\n",
    "    optimizer.apply_gradients(zip(grads, self.variables))\n",
    "        \n",
    "        \n",
    "  def compute_output(self, X):\n",
    "    \"\"\"\n",
    "    Custom method to obtain output tensor during forward pass\n",
    "    \"\"\"\n",
    "    # Cast X to float32\n",
    "    X_tf = tf.cast(X, dtype=tf.float32)\n",
    "    #Remember to normalize your dataset before moving forward\n",
    "    # Compute values in hidden layer1\n",
    "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "    hhat1 = tf.nn.relu(what1)\n",
    "    hhat1_1 = tf.nn.dropout(hhat1, 0.25)\n",
    "\n",
    "    # Compute values in hidden layer2\n",
    "    what2 = tf.matmul(hhat1_1, self.W2) + self.b2\n",
    "    hhat2 = tf.nn.relu(what2)\n",
    "    hhat2_1 = tf.nn.dropout(hhat2, 0.25)\n",
    "    \n",
    "    # Compute output\n",
    "    output = tf.matmul(hhat2_1, self.W3) + self.b3\n",
    "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
    "    #Second add tf.Softmax(output) and then return this variable\n",
    "    output = tf.nn.softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b04ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23a7aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 1 - Average celoss:= 100.76181666666666- Acc:= 0.20085015892982483 \n",
      "Number of Epoch = 2 - Average celoss:= 55.37209583333333- Acc:= 0.4852829873561859 \n",
      "Number of Epoch = 3 - Average celoss:= 30.455820833333334- Acc:= 0.6421337127685547 \n",
      "Number of Epoch = 4 - Average celoss:= 16.741703125- Acc:= 0.7432505488395691 \n",
      "Number of Epoch = 5 - Average celoss:= 9.141228125- Acc:= 0.7991493940353394 \n",
      "Number of Epoch = 6 - Average celoss:= 5.0171765625- Acc:= 0.8411981463432312 \n",
      "Number of Epoch = 7 - Average celoss:= 2.7636703125- Acc:= 0.8655471205711365 \n",
      "Number of Epoch = 8 - Average celoss:= 1.5291217447916667- Acc:= 0.8767290711402893 \n",
      "Number of Epoch = 9 - Average celoss:= 0.8527438802083334- Acc:= 0.8831782341003418 \n",
      "Number of Epoch = 10 - Average celoss:= 0.4820863932291667- Acc:= 0.8850458264350891 \n",
      "Number of Epoch = 11 - Average celoss:= 0.2788782552083333- Acc:= 0.8901106715202332 \n",
      "Number of Epoch = 12 - Average celoss:= 0.167387646484375- Acc:= 0.8930267691612244 \n",
      "Number of Epoch = 13 - Average celoss:= 0.10576959635416666- Acc:= 0.8962932229042053 \n",
      "Number of Epoch = 14 - Average celoss:= 0.07166637369791666- Acc:= 0.8988265991210938 \n",
      "Number of Epoch = 15 - Average celoss:= 0.05246337890625- Acc:= 0.9033094644546509 \n",
      "Number of Epoch = 16 - Average celoss:= 0.041759663899739584- Acc:= 0.9054774641990662 \n",
      "Number of Epoch = 17 - Average celoss:= 0.03548543294270833- Acc:= 0.9090428352355957 \n",
      "Number of Epoch = 18 - Average celoss:= 0.03189010416666667- Acc:= 0.9108920693397522 \n",
      "Number of Epoch = 19 - Average celoss:= 0.02967367960611979- Acc:= 0.9143247008323669 \n",
      "Number of Epoch = 20 - Average celoss:= 0.02842791951497396- Acc:= 0.9148094058036804 \n",
      "Number of Epoch = 21 - Average celoss:= 0.027302339680989583- Acc:= 0.9187082648277283 \n",
      "Number of Epoch = 22 - Average celoss:= 0.0265965576171875- Acc:= 0.9203923940658569 \n",
      "Number of Epoch = 23 - Average celoss:= 0.02616063435872396- Acc:= 0.9220907092094421 \n",
      "Number of Epoch = 24 - Average celoss:= 0.02569833780924479- Acc:= 0.9241896867752075 \n",
      "Number of Epoch = 25 - Average celoss:= 0.025336163330078126- Acc:= 0.924024224281311 \n",
      "Number of Epoch = 26 - Average celoss:= 0.024967047119140624- Acc:= 0.9260910749435425 \n",
      "Number of Epoch = 27 - Average celoss:= 0.024734039306640625- Acc:= 0.9270739555358887 \n",
      "Number of Epoch = 28 - Average celoss:= 0.024453934733072915- Acc:= 0.9280396103858948 \n",
      "Number of Epoch = 29 - Average celoss:= 0.024206087239583333- Acc:= 0.9290568828582764 \n",
      "Number of Epoch = 30 - Average celoss:= 0.024125227864583335- Acc:= 0.9298743605613708 \n",
      "\n",
      "Total time taken (in seconds): 2225.20\n"
     ]
    }
   ],
   "source": [
    "# Initialize model using CPU\n",
    "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_output, device='cpu')\n",
    "\n",
    "# Array to store accuracy and loss\n",
    "loss_with_epoch = []\n",
    "acc_with_epoch = []\n",
    "\n",
    "time_start = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  ac = 0\n",
    "  count = 0\n",
    "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
    "  lt = 0\n",
    "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
    "  for inputs, outputs in train_ds:\n",
    "    preds = mlp_on_cpu.forward(inputs)\n",
    "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
    "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
    "    mlp_on_cpu.backward(inputs, outputs)\n",
    "    ac = ac+mlp_on_cpu.accuracy(preds, outputs)\n",
    "    #ac = mlp_on_cpu.accuracy(preds, outputs)\n",
    "    count += 1\n",
    "  print('Number of Epoch = {} - Average celoss:= {}- Acc:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], ac/count))\n",
    "  loss_with_epoch.append(np.sum(loss_total) / X_train.shape[0])\n",
    "  acc_with_epoch.append(ac/count)\n",
    "time_taken = time.time() - time_start\n",
    "\n",
    "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
    "#For per epoch_time = Total_Time / Number_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ad19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = [i for i in range(1,31)]\n",
    "line1, = plt.plot(x, acc_with_epoch, label='accr')\n",
    "line2, = plt.plot(x, loss_with_epoch, label='ce loss')\n",
    "#plt.plot(x, acc_with_epoch, label='accr')\n",
    "plt.legend(handles=[line1, line2], loc='best')\n",
    "plt.grid(b=True, color='aqua', alpha=0.6, linestyle='dashdot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0ff216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test celoss: 0.0900 and accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
    "#test_loss_total = 0.0\n",
    "for inputs, outputs in test_ds:\n",
    "  preds = mlp_on_cpu.forward(inputs)\n",
    "  #b = mlp_on_default.loss(preds, outputs)\n",
    "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
    "  ac = mlp_on_cpu.accuracy(preds, outputs)\n",
    "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
    "# print(X_train.shape[0])\n",
    "# print(test_loss_total.numpy())\n",
    "# print(b)\n",
    "print('Test celoss: {:.4f} and accuracy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0], ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a554bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
