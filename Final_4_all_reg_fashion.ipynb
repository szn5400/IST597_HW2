{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04d9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f110e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Define the One-hot Encoder\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "# Load MNIST data\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Fit and transform training data\n",
    "ohe.fit(y_train)\n",
    "transformed_train = ohe.transform(y_train).toarray()\n",
    "\n",
    "# Fit and transform testing data\n",
    "ohe.fit(y_test)\n",
    "transformed_test = ohe.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b98a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000, 10)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(x_train.shape))\n",
    "print('Y_train: ' + str(transformed_train.shape))\n",
    "print('X_test:  '  + str(x_test.shape))\n",
    "print('Y_test:  '  + str(transformed_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4871e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_mod = x_train.reshape(60000, 784)\n",
    "train_y_mod = transformed_train\n",
    "test_X_mod = x_test.reshape(10000, 784)\n",
    "test_y_mod = transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937068cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_input = 784\n",
    "size_hidden1 = 512\n",
    "size_hidden2 = 256\n",
    "size_output = 10\n",
    "number_of_train_examples = 60000\n",
    "number_of_test_examples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c30a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X_train = tf.keras.utils.normalize(train_X_mod, axis=1)\n",
    "y_train = train_y_mod\n",
    "X_test = test_X_mod\n",
    "y_test = test_y_mod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d8d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "# Split dataset into batches\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(128)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8257b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "  def __init__(self, size_input, size_hidden1, size_hidden2, size_output, device=None):\n",
    "    \"\"\"\n",
    "    size_input: int, size of input layer\n",
    "    size_hidden1: int, size of hidden layer 1\n",
    "    size_hidden2: int, size of hodden layer 2\n",
    "    size_output: int, size of output layer\n",
    "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
    "    \"\"\"\n",
    "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_output, self.device =\\\n",
    "    size_input, size_hidden1, size_hidden2, size_output, device\n",
    "    \n",
    "    # Initialize weights between input layer and hidden layer\n",
    "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
    "    # Initialize biases for hidden layer\n",
    "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
    "    # Initialize weights between input layer and hidden layer\n",
    "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
    "    # Initialize biases for hidden layer\n",
    "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
    "     # Initialize weights between hidden layer and output layer\n",
    "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output]))\n",
    "    # Initialize biases for output layer\n",
    "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
    "    \n",
    "    # Define variables to be updated during backpropagation\n",
    "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "    \n",
    "  def forward(self, X):\n",
    "    \"\"\"\n",
    "    forward pass\n",
    "    X: Tensor, inputs\n",
    "    \"\"\"\n",
    "    if self.device is not None:\n",
    "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
    "        self.y = self.compute_output(X)\n",
    "    else:\n",
    "      self.y = self.compute_output(X)\n",
    "      \n",
    "    return self.y\n",
    "  \n",
    "  def loss(self, y_pred, y_true):\n",
    "    '''\n",
    "    y_pred - Tensor of shape (batch_size, size_output)\n",
    "    y_true - Tensor of shape (batch_size, size_output)\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    #return tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
    "    #print(y_true_tf)\n",
    "    #print(y_pred_tf)\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    loss_val = cce(y_true_tf, y_pred_tf)\n",
    "    regularizer = tf.nn.l2_loss(self.W1)+tf.nn.l2_loss(self.W2)\n",
    "    loss_val = tf.reduce_mean(loss_val + 0.01 * regularizer)\n",
    "    \n",
    "    #print(loss_val)\n",
    "    return loss_val\n",
    "\n",
    "  def accuracy(self, y_pred, y_true):\n",
    "    '''\n",
    "    y_pred - Tensor of shape (batch_size, size_output)\n",
    "    y_true - Tensor of shape (batch_size, size_output)\n",
    "    '''\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    #y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
    "    print(y_true_tf)\n",
    "    print(y_pred_tf)\n",
    "    ## CALCULATING COST AND ACCURACY\n",
    "    #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_preds, labels=y))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    #print(correct_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #print(ac)\n",
    "    return accuracy\n",
    "    '''\n",
    "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "    #y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)    \n",
    "    correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    #print(correct_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "  \n",
    "  def backward(self, X_train, y_train):\n",
    "    \"\"\"\n",
    "    backward pass\n",
    "    \"\"\"\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "    with tf.GradientTape() as tape:\n",
    "      predicted = self.forward(X_train)\n",
    "      current_loss = self.loss(predicted, y_train)\n",
    "    grads = tape.gradient(current_loss, self.variables)\n",
    "    optimizer.apply_gradients(zip(grads, self.variables))\n",
    "        \n",
    "        \n",
    "  def compute_output(self, X):\n",
    "    \"\"\"\n",
    "    Custom method to obtain output tensor during forward pass\n",
    "    \"\"\"\n",
    "    # Cast X to float32\n",
    "    X_tf = tf.cast(X, dtype=tf.float32)\n",
    "    #Remember to normalize your dataset before moving forward\n",
    "    # Compute values in hidden layer1\n",
    "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "    hhat1 = tf.nn.relu(what1)\n",
    "    hhat1_1 = tf.nn.dropout(hhat1, 0.25)\n",
    "\n",
    "    # Compute values in hidden layer2\n",
    "    what2 = tf.matmul(hhat1_1, self.W2) + self.b2\n",
    "    hhat2 = tf.nn.relu(what2)\n",
    "    hhat2_1 = tf.nn.dropout(hhat2, 0.25)\n",
    "    \n",
    "    # Compute output\n",
    "    output = tf.matmul(hhat2_1, self.W3) + self.b3\n",
    "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
    "    #Second add tf.Softmax(output) and then return this variable\n",
    "    output = tf.nn.softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b04ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "NUM_EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23a7aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 1 - Average celoss:= 100.72511666666666- Acc:= 0.2486167550086975 \n",
      "Number of Epoch = 2 - Average celoss:= 55.35055833333333- Acc:= 0.5124160051345825 \n",
      "Number of Epoch = 3 - Average celoss:= 30.43666875- Acc:= 0.6587673425674438 \n",
      "Number of Epoch = 4 - Average celoss:= 16.70240104166667- Acc:= 0.6991162896156311 \n",
      "Number of Epoch = 5 - Average celoss:= 9.133408333333334- Acc:= 0.708834171295166 \n",
      "Number of Epoch = 6 - Average celoss:= 5.025085416666666- Acc:= 0.7421330809593201 \n",
      "Number of Epoch = 7 - Average celoss:= 2.77432734375- Acc:= 0.7624335289001465 \n",
      "Number of Epoch = 8 - Average celoss:= 1.5401354166666668- Acc:= 0.7744008898735046 \n",
      "Number of Epoch = 9 - Average celoss:= 0.8633239583333333- Acc:= 0.7802013158798218 \n",
      "Number of Epoch = 10 - Average celoss:= 0.49243971354166666- Acc:= 0.7826511263847351 \n",
      "Number of Epoch = 11 - Average celoss:= 0.28872353515625- Acc:= 0.7877507209777832 \n",
      "Number of Epoch = 12 - Average celoss:= 0.17693719075520833- Acc:= 0.7886009812355042 \n",
      "Number of Epoch = 13 - Average celoss:= 0.11528483072916666- Acc:= 0.7924015522003174 \n",
      "Number of Epoch = 14 - Average celoss:= 0.08118929036458333- Acc:= 0.7960178852081299 \n",
      "Number of Epoch = 15 - Average celoss:= 0.062289990234375- Acc:= 0.7986664772033691 \n",
      "Number of Epoch = 16 - Average celoss:= 0.05179300537109375- Acc:= 0.7997688055038452 \n",
      "Number of Epoch = 17 - Average celoss:= 0.04575499267578125- Acc:= 0.8037519454956055 \n",
      "Number of Epoch = 18 - Average celoss:= 0.042274393717447914- Acc:= 0.8050017952919006 \n",
      "Number of Epoch = 19 - Average celoss:= 0.03991382242838542- Acc:= 0.8096016645431519 \n",
      "Number of Epoch = 20 - Average celoss:= 0.03876180419921875- Acc:= 0.8089342713356018 \n",
      "Number of Epoch = 21 - Average celoss:= 0.03775730794270833- Acc:= 0.811418890953064 \n",
      "Number of Epoch = 22 - Average celoss:= 0.037124385579427086- Acc:= 0.8114688992500305 \n",
      "Number of Epoch = 23 - Average celoss:= 0.03658232014973958- Acc:= 0.8145686984062195 \n",
      "Number of Epoch = 24 - Average celoss:= 0.03602639973958333- Acc:= 0.816167414188385 \n",
      "Number of Epoch = 25 - Average celoss:= 0.03581261393229167- Acc:= 0.8162340521812439 \n",
      "Number of Epoch = 26 - Average celoss:= 0.03538116048177083- Acc:= 0.8210681080818176 \n",
      "Number of Epoch = 27 - Average celoss:= 0.03513014729817708- Acc:= 0.8189011812210083 \n",
      "Number of Epoch = 28 - Average celoss:= 0.03485459391276042- Acc:= 0.8196836113929749 \n",
      "Number of Epoch = 29 - Average celoss:= 0.03461031494140625- Acc:= 0.8221855759620667 \n",
      "Number of Epoch = 30 - Average celoss:= 0.03449452718098958- Acc:= 0.8231515884399414 \n",
      "Number of Epoch = 31 - Average celoss:= 0.03429405924479167- Acc:= 0.8241183161735535 \n",
      "Number of Epoch = 32 - Average celoss:= 0.03429638264973958- Acc:= 0.8227012753486633 \n",
      "Number of Epoch = 33 - Average celoss:= 0.0341795166015625- Acc:= 0.8240519762039185 \n",
      "Number of Epoch = 34 - Average celoss:= 0.034048667399088545- Acc:= 0.8236678838729858 \n",
      "Number of Epoch = 35 - Average celoss:= 0.03407737426757813- Acc:= 0.8252357840538025 \n",
      "Number of Epoch = 36 - Average celoss:= 0.034006917317708336- Acc:= 0.8250667452812195 \n",
      "Number of Epoch = 37 - Average celoss:= 0.03387763468424479- Acc:= 0.8256170153617859 \n",
      "Number of Epoch = 38 - Average celoss:= 0.03399281819661459- Acc:= 0.823883056640625 \n",
      "Number of Epoch = 39 - Average celoss:= 0.03371468912760417- Acc:= 0.8270347714424133 \n",
      "Number of Epoch = 40 - Average celoss:= 0.03376712646484375- Acc:= 0.8263017535209656 \n",
      "\n",
      "Total time taken (in seconds): 3276.08\n"
     ]
    }
   ],
   "source": [
    "# Initialize model using CPU\n",
    "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_output, device='cpu')\n",
    "\n",
    "# Array to store accuracy and loss\n",
    "loss_with_epoch = []\n",
    "acc_with_epoch = []\n",
    "\n",
    "time_start = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  ac = 0\n",
    "  count = 0\n",
    "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
    "  lt = 0\n",
    "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
    "  for inputs, outputs in train_ds:\n",
    "    preds = mlp_on_cpu.forward(inputs)\n",
    "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
    "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
    "    mlp_on_cpu.backward(inputs, outputs)\n",
    "    ac = ac+mlp_on_cpu.accuracy(preds, outputs)\n",
    "    #ac = mlp_on_cpu.accuracy(preds, outputs)\n",
    "    count += 1\n",
    "  print('Number of Epoch = {} - Average celoss:= {}- Acc:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], ac/count))\n",
    "  loss_with_epoch.append(np.sum(loss_total) / X_train.shape[0])\n",
    "  acc_with_epoch.append(ac/count)\n",
    "time_taken = time.time() - time_start\n",
    "\n",
    "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
    "#For per epoch_time = Total_Time / Number_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ad19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = [i for i in range(1,41)]\n",
    "line1, = plt.plot(x, acc_with_epoch, label='accr')\n",
    "line2, = plt.plot(x, loss_with_epoch, label='ce loss')\n",
    "#plt.plot(x, acc_with_epoch, label='accr')\n",
    "plt.legend(handles=[line1, line2], loc='best')\n",
    "plt.grid(b=True, color='aqua', alpha=0.6, linestyle='dashdot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0ff216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test celoss: 0.3623 and accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
    "#test_loss_total = 0.0\n",
    "for inputs, outputs in test_ds:\n",
    "  preds = mlp_on_cpu.forward(inputs)\n",
    "  #b = mlp_on_default.loss(preds, outputs)\n",
    "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
    "  ac = mlp_on_cpu.accuracy(preds, outputs)\n",
    "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
    "# print(X_train.shape[0])\n",
    "# print(test_loss_total.numpy())\n",
    "# print(b)\n",
    "print('Test celoss: {:.4f} and accuracy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0], ac))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a554bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
